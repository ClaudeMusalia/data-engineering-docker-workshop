{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1b9bc40-cdea-4fb9-bacc-8b98faef1566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5ddd3bb-4dd8-4e9c-8e7d-0c4e8809513d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 18)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read a sample of the dataset\n",
    "prefix = 'https://github.com/DataTalksClub/nyc-tlc-data/releases/download/yellow/'\n",
    "url = f'{prefix}/yellow_tripdata_2021-01.csv.gz'\n",
    "url\n",
    "df = pd.read_csv(prefix + 'yellow_tripdata_2021-01.csv.gz', nrows=100)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "df.head()\n",
    "\n",
    "# Check data types of each column\n",
    "df.dtypes\n",
    "\n",
    "# Check data shape\n",
    "df.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96ad2bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the data types for each column\n",
    "dtype = {\n",
    "    \"VendorID\": \"Int64\",\n",
    "    \"passenger_count\": \"Int64\",\n",
    "    \"trip_distance\": \"float64\",\n",
    "    \"RatecodeID\": \"Int64\",\n",
    "    \"store_and_fwd_flag\": \"string\",\n",
    "    \"PULocationID\": \"Int64\",\n",
    "    \"DOLocationID\": \"Int64\",\n",
    "    \"payment_type\": \"Int64\",\n",
    "    \"fare_amount\": \"float64\",\n",
    "    \"extra\": \"float64\",\n",
    "    \"mta_tax\": \"float64\",\n",
    "    \"tip_amount\": \"float64\",\n",
    "    \"tolls_amount\": \"float64\",\n",
    "    \"improvement_surcharge\": \"float64\",\n",
    "    \"total_amount\": \"float64\",\n",
    "    \"congestion_surcharge\": \"float64\"\n",
    "}\n",
    "\n",
    "parse_dates = [\n",
    "    \"tpep_pickup_datetime\",\n",
    "    \"tpep_dropoff_datetime\"\n",
    "]\n",
    "\n",
    "df = pd.read_csv(\n",
    "    prefix + 'yellow_tripdata_2021-01.csv.gz',\n",
    "    nrows=2000000000,\n",
    "    dtype=dtype,\n",
    "    parse_dates=parse_dates\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88c0ed61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m119 packages\u001b[0m \u001b[2min 0.60ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m11 packages\u001b[0m \u001b[2min 0.19ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Ingesting data into PostgreSQL database using SQLAlchemy \n",
    "# Install sqlalchemy and psycopg2-binary if not already installed\n",
    "!uv add sqlalchemy psycopg2-binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8215e712-e662-4c9a-8f0d-8014e81a2f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "caee0d3a-d02d-48de-8aaa-820dd9488329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the table/schema. If the table with this name already exists, we are going to drop it and create a new one. \n",
    "df.head(0).to_sql(name='yellow_taxi_data', con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bee1765c-f825-42d3-83ea-4fb3eeecc55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1369765"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9dedcfcb-5a1d-4caf-84d9-75f313a464b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE yellow_taxi_data (\n",
      "\t\"VendorID\" BIGINT, \n",
      "\ttpep_pickup_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\ttpep_dropoff_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tpassenger_count BIGINT, \n",
      "\ttrip_distance FLOAT(53), \n",
      "\t\"RatecodeID\" BIGINT, \n",
      "\tstore_and_fwd_flag TEXT, \n",
      "\t\"PULocationID\" BIGINT, \n",
      "\t\"DOLocationID\" BIGINT, \n",
      "\tpayment_type BIGINT, \n",
      "\tfare_amount FLOAT(53), \n",
      "\textra FLOAT(53), \n",
      "\tmta_tax FLOAT(53), \n",
      "\ttip_amount FLOAT(53), \n",
      "\ttolls_amount FLOAT(53), \n",
      "\timprovement_surcharge FLOAT(53), \n",
      "\ttotal_amount FLOAT(53), \n",
      "\tcongestion_surcharge FLOAT(53)\n",
      ")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#schema that will be created in our database\n",
    "print(pd.io.sql.get_schema(df, name='yellow_taxi_data', con=engine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b00fc24c-0d19-4b95-8f57-1ada4c9b1cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ingesting data in chunks since we cannot take the whole dataset at once. We will do batches and use an iterator for that. \n",
    "df_iter = pd.read_csv(\n",
    "    url,\n",
    "    dtype=dtype,\n",
    "    parse_dates=parse_dates,\n",
    "    iterator=True,\n",
    "    chunksize=100000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8d0b662-a183-4fd2-ab84-0406e077d0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = next(df_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ffea1e32-3f32-4cff-83bd-b7adf8da890d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "69765\n"
     ]
    }
   ],
   "source": [
    "#Iterate over chunks. \n",
    "for df_chunk in df_iter:\n",
    "    print(len(df_chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45b8429f-96d0-41db-b034-eeb3b66fe93b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "765"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For inserting data\n",
    "df_chunk.to_sql(name='yellow_taxi_data', con=engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0a9da9ed-9fa8-42aa-9d1c-2e64067cb1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m120 packages\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m12 packages\u001b[0m \u001b[2min 0.19ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#to see progress of data ingestion\n",
    "!uv add tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "32a1da5d-fbe3-4593-9f0a-c22fb08e9ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b896ba82-a9ed-4c9d-bc67-53c3a35061de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9611dbfe2fd94401b5a71cf9da0d3c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Completing the ingestion loop\n",
    "first = True\n",
    "\n",
    "for df_chunk in tqdm(df_iter):\n",
    "\n",
    "    if first:\n",
    "        # Create table schema (no data)\n",
    "        df_chunk.head(0).to_sql(\n",
    "            name=\"yellow_taxi_data\",\n",
    "            con=engine,\n",
    "            if_exists=\"replace\"\n",
    "        )\n",
    "        first = False\n",
    "        print(\"Table created\")\n",
    "\n",
    "    # Insert chunk\n",
    "    df_chunk.to_sql(\n",
    "        name=\"yellow_taxi_data\",\n",
    "        con=engine,\n",
    "        if_exists=\"append\"\n",
    "    )\n",
    "\n",
    "    print(\"Inserted:\", len(df_chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352ed931-e0a1-40d3-a789-78fe6532e77f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
